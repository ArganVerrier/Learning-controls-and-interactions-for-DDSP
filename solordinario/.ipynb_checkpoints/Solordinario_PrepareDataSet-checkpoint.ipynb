{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réarrengement data Solordinario\n",
    "\n",
    "Création d'un dataset à partir de solordinario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob \n",
    "import os.path\n",
    "import scipy.io.wavfile as wavfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "\n",
    "def listdirectory(path): \n",
    "    fichier=[] \n",
    "    l = glob.glob(path+'\\\\*') \n",
    "    for i in l: \n",
    "        if os.path.isdir(i): fichier.extend(listdirectory(i)) \n",
    "        else: fichier.append(i) \n",
    "    return fichier\n",
    "\n",
    "files = listdirectory(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = 3 #durée à conserver en sec\n",
    "for file in files:\n",
    "    Fe, sig = wavfile.read(file)\n",
    "    new_dir = 'data_2/'+file[5:]\n",
    "    wavfile.write(new_dir, Fe, sig[:long*Fe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionnaire avec Pitch et Velocite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descriptors\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'data_2'\n",
    "files = listdirectory(path)\n",
    "nb_files = len(files)\n",
    "print(nb_files)\n",
    "sample_per_sec = 250\n",
    "\n",
    "dict_env = {'file_name' : [[]]*nb_files, 'env' : [[]]*nb_files, 'vel' : [[]]*nb_files, 'pitch' : [[]]*nb_files, 'corde' : [[]]*nb_files}\n",
    "f = 0\n",
    "\n",
    "for file in files:\n",
    "    name = file[7:]\n",
    "    vel = file[14:16]\n",
    "    corde = file[17:19]\n",
    "    if file[-6]=='#':\n",
    "        pitch = file[-7:-4]\n",
    "    else :\n",
    "        pitch = file[-6:-4]\n",
    "        \n",
    "    Fe, sig = wavfile.read(file)\n",
    "    sig = sig.astype(np.float32)\n",
    "    env = np.zeros([2,long*sample_per_sec])\n",
    "    env[0,:] = descriptors.extract_loudness(sig, sampling_rate=Fe, block_size=int(Fe/250), n_fft=2048)[:long*sample_per_sec]\n",
    "    env[1,:] = descriptors.extract_pitch(sig, sampling_rate=Fe, block_size=int(Fe/250))[:long*sample_per_sec]\n",
    "    \n",
    "    dict_env['file_name'][f] = file\n",
    "    dict_env['env'][f] = env\n",
    "    dict_env['vel'][f] = vel\n",
    "    dict_env['pitch'][f] = pitch\n",
    "    dict_env['corde'][f] = corde\n",
    "    print(f)\n",
    "    f += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save\n",
    "np.save('data_dict.npy', dict_env) \n",
    "\n",
    "Load\n",
    "dict_r = np.load('data_dict.npy').item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création dataset pour torch #\n",
    "\n",
    "format : N * envLoudness * envPitch * vel * note\n",
    "- N : nombre de samples\n",
    "- envLoudness : enveloppe d'intensité\n",
    "- envPitch : enveloppe de fondamentale\n",
    "- vel : vélocité (1:3)\n",
    "- note : note midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi_numbers\n",
    "\n",
    "def convNote2MIDI(noteOct):\n",
    "    octave=int(noteOct[len(noteOct)-1])\n",
    "    note=noteOct[0:len(noteOct)-1]\n",
    "    midiNote=midi_numbers.note_to_number(note, octave)\n",
    "    return float(midiNote)\n",
    "\n",
    "#convNote2MIDI(pitch[0])\n",
    "\n",
    "def convVel2Nbr(velocity, sym=['pp', 'mf', 'ff']):\n",
    "    return float(sym.index(velocity)+1)\n",
    "    \n",
    "def arrayNote(notes):\n",
    "    midiNotes=np.zeros(notes.shape)\n",
    "    for ind in range(notes.size):\n",
    "        midiNotes[ind]=convNote2MIDI(notes[ind])\n",
    "    return midiNotes\n",
    "\n",
    "def arrayVel(velocities):\n",
    "    nbrVel=np.zeros(velocities.shape)\n",
    "    for ind in range(velocities.size):\n",
    "        nbrVel[ind]=convVel2Nbr(velocities[ind])\n",
    "    return nbrVel\n",
    "\n",
    "    \n",
    "Notes=arrayNote(pitch)\n",
    "Vel=arrayVel(vel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import descriptors\n",
    "import torch\n",
    "import numpy as np\n",
    "N=279\n",
    "dict_r = np.load('data_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "train_db = torch.zeros(torch.tensor(dict_r['env']).shape)\n",
    "\n",
    "\n",
    "envLoudness=np.array(dict_r[\"env\"])[:,0,:]\n",
    "envPitch=np.array(dict_r[\"env\"])[:,1,:]\n",
    "fileName=np.array(dict_r[\"file_name\"]).reshape(N, 1)\n",
    "pitch=np.array(dict_r[\"pitch\"]).reshape(N, 1)\n",
    "vel=np.array(dict_r[\"vel\"]).reshape(N, 1)\n",
    "corde=np.array(dict_r[\"corde\"]).reshape(N, 1)\n",
    "\n",
    "trainDb=np.zeros((279, 2, 750, 1, 1))\n",
    "Notes=arrayNote(pitch)\n",
    "Vel=arrayVel(vel)\n",
    "\n",
    "#format du dataset : [N, envLoudness, envPitch, velocitv(0,127), note (MIDI)]\n",
    "\n",
    "#for ind in range(N):\n",
    "#    trainDb[ind, :, :, 0, 0]=env[ind, :, :]\n",
    "#for sample in dict_r['env']:\n",
    "#    train_db[i,:,:] = sample\n",
    "#    i+=1\n",
    "    \n",
    "#train_dataset =  torch.utils.data.TensorDataset(torch.from_numpy(train_db))\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDb=torch.zeros(279, 750, 750, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=trainDb[1, :, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pitchEnv[1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=loudEnv.reshape((279, 2, 750, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=fileName.reshape(279, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data_2\\\\Vn-ord-ff-1c-C#7.wav'], dtype='<U28')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.index('mf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.array(dict_r[\"env\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 2, 750)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
